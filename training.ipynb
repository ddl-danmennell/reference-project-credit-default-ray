{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67696567-2a05-4457-8235-961fc882cfd2",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "For this demo we'll use the freely available Statlog (German Credit Data) Data Set, which can be downloaded from [Kaggle](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)). This dataset classifies customers based on a set of attributes into two credit risk groups - good or bad. The majority of the attributes in this data set are categorical, and they are symbolically encoded. For example, attribute 1 represents the status of an existing checking account and can take one of the following values:\n",
    "\n",
    "A11 : ... < 0 DM\n",
    "\n",
    "A12 : 0 <= ... < 200 DM\n",
    "\n",
    "A13 : ... >= 200 DM / salary assignments for at least 1 year\n",
    "\n",
    "A14 : no checking account\n",
    "\n",
    "A comprehensive list of all attributes and symbol codes is given in the [document](https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc) that accompanies the original dataset. \n",
    "\n",
    "The data we use in this demo has also been balanced and upsampled (see the [Data Generation](./data_generation.ipynb) notebook for reference)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99567b3f-2224-40eb-9abe-0be5747553a1",
   "metadata": {},
   "source": [
    "## Seting up and connecting to Ray\n",
    "\n",
    "\n",
    "Let's start by loading all the libraries needed for the notebook and by setting up default data paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90dacfb-7731-4433-a91d-6bd2b79c81c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ray\n",
    "import glob\n",
    "import eli5\n",
    "\n",
    "import xgboost_ray as xgbr\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from ray import tune\n",
    "\n",
    "DATA_ROOT = os.path.join(\"/mnt/data\", os.environ[\"DOMINO_PROJECT_NAME\"], \"data\") \n",
    "MODEL_ROOT = \"/mnt/artifacts\"\n",
    "TUNE_ROOT = os.path.join(\"/mnt/data\", os.environ[\"DOMINO_PROJECT_NAME\"], \"ray_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc47b91-d8f6-49b6-915e-244688dc9d64",
   "metadata": {},
   "source": [
    "In this demo we'll use a dataset of a modest size (approx. 700 MB). Unfortunately, the standard Python libraries for data processing and machine learning Pandas and NumPy have never been designed with large datasets in mind. They rely on being able to fit the entire data in-memory with Pandas data frames having a hard theoretical limit of 100GB. In practice, the amount of data these libraries can handle is also restricted by the amount of physical memory available to the container that runs them, thus they'll have challenges handling even the 700 MB needed for our demo dataset. Trying to load our training data into a simple Pandas data frame using the code below will likely crash the Jupyter kernel.\n",
    "\n",
    "``` \n",
    "# Do not run this code - it will likely crash the Jupyter kernel \n",
    "# (depending on the HW tier running the kernel)\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "all_files = glob.glob(DATA_ROOT + \"/train_data_*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "training_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "training_df.head()\n",
    "```\n",
    "\n",
    "To circumvent these restrictions Domino provides support for a number of industry-standard distributed computing frameworks like Ray, Dask, and Spark. In this demo we will use [On-Demand Ray](https://docs.dominodatalab.com/en/latest/user_guide/d13903/on-demand-ray-overview/). \n",
    "\n",
    "Ray is a general framework that enables you to quickly parallelize existing Python code, but it is also talked about as a \"framework for building frameworks\". Indeed, there are a growing number of domain-specific libraries that work on top of Ray.\n",
    "\n",
    "![Ray](./images/ray.png)\n",
    "\n",
    "For example:\n",
    "\n",
    "* RaySGD - a library for distributed deep learning, which provides wrappers around PyTorch and TensorFlow\n",
    "* RLlib - a library for reinforcement learning, which also natively supports TensorFlow, TensorFlow Eager, and PyTorch\n",
    "* RayServe - a scalable, model-serving library\n",
    "* Ray Tune - a hyperparameter optimization framework, most commonly used for deep and reinforcement learning\n",
    "\n",
    "In this demo we'll use [Ray Tune](https://docs.ray.io/en/latest/tune/index.html) for hyperparameter optimisation and [XGBoost on Ray](https://github.com/ray-project/xgboost_ray) for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea8db6-c2cf-4e87-bc36-ef30a6c6f223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We'll set up Ray for 2 workers, 4 CPUs each (12 CPUs in total, counting the head node).\n",
    "\n",
    "RAY_ACTORS = 3\n",
    "RAY_CPUS_PER_ACTOR = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5adb8cb-2d41-43fc-8e2a-023ba669ec83",
   "metadata": {},
   "source": [
    "Let's connect to Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab834d1d-8734-403b-abf1-485b9952bb17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if ray.is_initialized() == False:\n",
    "    service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "    service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "    ray.init(f\"ray://{service_host}:{service_port}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03916af-831e-4934-84f6-1814a86ec6fb",
   "metadata": {},
   "source": [
    "Let's confirm we have the expected cluster configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc390a-ee65-4abf-bc25-71985b921289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239b2e73-b9d9-486e-baba-f456b8c7e6b1",
   "metadata": {},
   "source": [
    "Now let's create a list of all the shards for our training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716569f8-6838-4571-b7da-7494fef8ad80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_files = glob.glob(os.path.join(DATA_ROOT, \"train_data*\"))\n",
    "val_files = glob.glob(os.path.join(DATA_ROOT, \"validation_data*\"))\n",
    "\n",
    "test_file = os.path.join(DATA_ROOT, \"test_data.csv\")\n",
    "\n",
    "target_col = \"credit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aef485-c29e-478b-b5b7-a3e05ee027e4",
   "metadata": {},
   "source": [
    "XGBoost-Ray provides a drop-in replacement for XGBoost's train function. To pass data, instead of using xgb.DMatrix we will have to use xgboost_ray.RayDMatrix. The RayDMatrix lazy loads data and stores it sharded in the Ray object store. The Ray XGBoost actors then access these shards to run their training on. Let's wrap our training, validation, and test sets into RayDMatrix objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ae7ab-9c91-4b89-aa65-acb27f759bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Although it is possible to specify the number of Actors when initializing the RayDMatrix, it is not necessary,\n",
    "#  and can cause a conflict if different from the number of Actors chosen for training.\n",
    "\n",
    "rdm_train = xgbr.RayDMatrix(train_files, label=target_col)\n",
    "rdm_val = xgbr.RayDMatrix(val_files, label=target_col)\n",
    "\n",
    "df_test = pd.read_csv(test_file)\n",
    "rdm_test = xgbr.RayDMatrix(df_test, label=target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e415ace-8763-4d9d-8f45-6ae9b7d6e5a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function verifies whether the data will support splitting into a given number of shards.\n",
    "# We use this to validate that our splits are compatible with the selected Ray cluster configuraiton (i.e. number of Ray nodes)\n",
    "\n",
    "rdm_train.assert_enough_shards_for_actors(len(train_files))\n",
    "rdm_train.assert_enough_shards_for_actors(len(val_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64ba99-513d-437e-ad62-6ffc5e746739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Will the read be distributed?\", rdm_train.distributed)\n",
    "print(\"Has any data been read yet?\", rdm_train.loaded) # Remember, lazy loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7a689-f25f-413c-80ad-de95790b5550",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e232a826-3f39-43fe-8a05-a9f521642324",
   "metadata": {},
   "source": [
    "Let's first try to train a single model in order to validate our setup. Feel free to switch to the Ray Web UI tab and observe the distribution of workload among the individual Ray nodes.\n",
    "\n",
    "A few things to note:\n",
    "\n",
    "* We are using “binary:logistic” – logistic regression for binary classification (*credit* is in {0,1}), which outputs probability\n",
    "* We are calculating both logloss and error as evaluation metrics. They don't impact the model fitting\n",
    "* We are passing the cluster topology via the xgb_ray_params objects so that the workload can be correctly distributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023dbe3e-5cba-44b0-a0dd-275b126a2261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set a few hyperparameters to specific values\n",
    "param = {\n",
    "    \"seed\":1234,\n",
    "    \"max_depth\":3,\n",
    "    \"eta\":0.1,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": [\"logloss\", \"error\"]\n",
    "}\n",
    "\n",
    "xgb_ray_params = xgbr.RayParams(\n",
    "    num_actors=RAY_ACTORS,\n",
    "    cpus_per_actor=RAY_CPUS_PER_ACTOR\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "evals_result = {}\n",
    "\n",
    "bst = xgbr.train(\n",
    "    param,\n",
    "    rdm_train,\n",
    "    num_boost_round=50,\n",
    "    verbose_eval=True,\n",
    "    evals_result=evals_result,\n",
    "    evals =[(rdm_train, \"train\"), (rdm_val, \"val\")],\n",
    "    ray_params=xgb_ray_params\n",
    ")\n",
    "\n",
    "print(\"Final training error: {:.4f}\".format(evals_result[\"train\"][\"error\"][-1]))\n",
    "print(\"Final validation error: {:.4f}\".format(evals_result[\"val\"][\"error\"][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f8914-984b-4011-845d-9cf5c90ccb54",
   "metadata": {},
   "source": [
    "Now that we've confirmed the pipeline we can move onto performing some hyperparameter tuning for finding an optimal model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe710a68-72ee-4bda-9a3b-c5b0a71f0215",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Hyperparameter tuning requires training many copies of a model, each with a different set of hyperparameters, and seeing which one performs the best. Each time we train a model, that is one trial. To do this in our Ray cluster, we can specify what resources to use:\n",
    "\n",
    "* Required CPU, Memory, and/or GPU per trial\n",
    "* Where to store intermediate results\n",
    "\n",
    "The `xgboost_ray` library includes a built-in method for generating a `PlacementGroupFactory` to pass to Ray Tune, based on the `RayParams` object used for XGBoost training. Resources can also be requested in a simpler dictionary format, e.g. `{\"cpu\": 2.0}`. As described in the [Tune docs](https://docs.ray.io/en/latest/tune/tutorials/tune-resources.html), by default Ray Tune will schedule N concurrent trials, using 1 CPU per trial, where N is the total number of CPUs available in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5014bbd6-42cb-4177-ba0a-5842ab77915d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the placement group factory to pass to Ray Tune\n",
    "# Notice how the tune resources are 1 CPU greater!\n",
    "xgb_tune_resources = xgb_ray_params.get_tune_resources()\n",
    "print(f\"We will pass a {type(xgb_tune_resources)} to Ray Tune.\")\n",
    "print(f\"It will request {xgb_tune_resources.required_resources} per trial.\")\n",
    "print(f\"The cluster has {ray.cluster_resources()['CPU']} CPU total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd6a9a-346d-4170-bbc3-180450e06410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Saving intermediate tune results to\", TUNE_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2959e8-ef2a-4a5a-8e6e-c627a3be5b7e",
   "metadata": {},
   "source": [
    "In this demo we will use a very simple search strategy called *a grid search*. This involves searching over a predefined grid of hyperparameter choices - and it's easy to imaging writing a simple for loop to implement it. However, for $n$ choices each of $k$ hyperparameters, a full grid search requires $O(n^k)$ trials and quickly becomes prohibitively expensive.\n",
    "\n",
    "Ray Tune provides much more sophisticated options for optimization. Instead of pre-defining a fixed grid to search over, Ray Tune allows specifying a [search space](https://docs.ray.io/en/releases-1.11.0/tune/key-concepts.html#search-spaces) with distributions of parameters. The number of trials over the search space is specified at a later stage in the `run()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6f30f-1349-47d3-8582-66a42b62aa39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"seed\": 1234,\n",
    "    \"eta\": tune.loguniform(3e-3, 3e-1),\n",
    "    \"max_depth\": tune.randint(2, 6),\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": [\"logloss\", \"error\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5b99f3-f8d7-4eb2-a592-fa35953fb522",
   "metadata": {},
   "source": [
    "For each trial, a config dictionary like the one we just defined, with the single value for each hyperparameter chosen for that trial, will be passed into a [trainable](https://docs.ray.io/en/releases-1.11.0/tune/key-concepts.html#search-algorithms) that we define and pass to Ray Tune. Below we have defined such a function to wrap training a single XGBoost model on Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba984d1f-46dd-41c7-9a31-08ec441bf14c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_trainer(config):\n",
    "    evals_result = {}\n",
    "    bst = xgbr.train(\n",
    "        params=config,\n",
    "        dtrain=rdm_train,\n",
    "        num_boost_round=50,\n",
    "        evals_result=evals_result,\n",
    "        evals=[(rdm_train, \"train\"), (rdm_val, \"val\")],\n",
    "        ray_params=xgb_ray_params\n",
    "    )\n",
    "    bst.save_model(\"model.xgb\") # This will go into the TUNE_ROOT directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd84a0-0ab6-4c8a-b531-0578603f373a",
   "metadata": {},
   "source": [
    "Finally, we can now run our trials. Here we bring together the previous few sections:\n",
    "\n",
    "* The training function\n",
    "* The search space defined in the config\n",
    "* The resources per trial and results location\n",
    "\n",
    "We control the number of trials over the search space via the `num_samples` argument (currently set to 10). We also rank the models based on the lowest validation set error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca740c1-c875-4d2b-9676-bbe415e30429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    my_trainer,\n",
    "    config=config,\n",
    "    resources_per_trial=xgb_tune_resources,\n",
    "    local_dir=TUNE_ROOT,\n",
    "    metric=\"val-error\",\n",
    "    mode=\"min\",\n",
    "    num_samples=10,\n",
    "    verbose=1,\n",
    "    progress_reporter=tune.JupyterNotebookReporter(overwrite=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b298667-ce7a-4248-bdc2-8fd5376fa9d2",
   "metadata": {},
   "source": [
    "Ray Tune returns an `ExperimentAnalysis` object which contains the results of the trials. We are only interested in its `best_config` property, which provides information on the best performing trial (according to our evaluation criteria)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cde0e8-c048-4da2-abb2-c52198d83ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis.best_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796209b3-72f0-474a-b703-0afd89959975",
   "metadata": {},
   "source": [
    "We now have the hyperparameters (*depth* and *learing rate*) that produce the best model. Luckily, we don't have to use them to train it from scratch as our training function automatically persists each attempted model. All we need to do now is to move the already trained variant to `/mnt` and ignore the others. We'll name the selected model `tune_best.xgb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb64dccd-415a-4d63-bd28-dcdf02879bc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy(\n",
    "    os.path.join(analysis.best_logdir, \"model.xgb\"),\n",
    "    os.path.join(MODEL_ROOT, \"tune_best.xgb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4be6b-d53d-4e94-988b-6b0917132922",
   "metadata": {},
   "source": [
    "Recall, that the model was selected using a validation set. We don't know its actual generalisation capability until we measure it on the test set.\n",
    "Let's go ahead and test how well it performs on unseen data. Note, that here we are also using Ray for the inference. This is not necessary. Later you will see that we can just unpickle the model and use standard XGBoost for the purposes of operationalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd5ad21-73a5-4410-b972-92ebbf6b21ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inference using Ray\n",
    "\n",
    "# Load the serialized model\n",
    "bst = xgb.Booster(model_file=os.path.join(MODEL_ROOT, \"tune_best.xgb\"))\n",
    "\n",
    "\n",
    "xgb_ray_params = xgbr.RayParams(\n",
    "    num_actors=RAY_ACTORS,\n",
    "    cpus_per_actor=RAY_CPUS_PER_ACTOR\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = xgbr.predict(bst, rdm_test, ray_params=xgb_ray_params)\n",
    "pred_class = (predictions > 0.5).astype(\"int\") \n",
    "actuals = df_test[target_col]\n",
    "print(\"Accuracy on test: {:.2f}\".format(accuracy_score(pred_class, actuals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9355849-d587-4e72-bc97-c50bf6e75549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e0d5c-81d3-4020-9a92-67aedf31f4eb",
   "metadata": {},
   "source": [
    "## Model explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87bd5c-276e-47dd-bf92-16a9744e3a85",
   "metadata": {},
   "source": [
    "The interest in interpretation of machine learning has been rapidly accelerating in the last decade. This can be attributed to the popularity that machine learning algorithms, and more specifically deep learning, has been gaining in various domains.\n",
    "\n",
    "According to Fox et al. (2017), the need for explainable AI is mainly motivated by the following three reasons:\n",
    "\n",
    "* The need for **trust** - if a doctor is recommending a treatment protocol based on a prediction from a neural network, this doctor must have absolute trust in the network's capability. This trust must be paramount when human lives are at stake.\n",
    "* The need for **interaction** - complex decision making systems often rely on Human–Autonomy Teaming (HAT), where the outcome is produced by joint efforts of one or more humans and one or more autonomous agents. This form of cooperation requires that the human operator is able to interact with the model for the purposes of better understanding or improving the automated recommendations.\n",
    "* The need for **transparency** - if a network makes an inappropriate recommendation or disagrees with a human expert, its behaviour must be explainable. There should be mechanisms that allow us to inspect the inner workings of the model's decision making process and get insight on what this decision was based on.\n",
    "\n",
    "In addition, regulators are introducing legal requirements around the use of automated decision making. For example, [article 22 of the General Data Protection Regulation](https://gdpr-info.eu/art-22-gdpr/) (GDPR) introduces the right of explanation - the power of an individual to demand an explanation on the reasons behind a model-based decision and to challenge the decision if it leads to a negative impact for the individual. The Defence Advanced Research Projects Agency (DARPA) in the US is supporting a major effort that seeks to facilitate AI explainability (see Turek, DARPA XAI).\n",
    "\n",
    "In this section of the notebook, we'll look into interpreting the inner workings of the model to better understand the encoded inductive biases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea426eb-01c6-469a-a06a-a0c3cf6e3e10",
   "metadata": {},
   "source": [
    "Let's begin by loading the model as a normal XGBoost model. We are no longer using Ray, as the model itself and the inference don't process large amounts of data.\n",
    "\n",
    "We'll also run another accuracy calculation on the test set (this time using a pure Pandas data frame) and make sure that the numbers agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb91a4b8-cd84-4cbf-acf8-d04ff0e72605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgc = xgb.Booster(model_file=os.path.join(MODEL_ROOT, \"tune_best.xgb\"))\n",
    "df_test_X = df_test.drop(target_col, axis=1)\n",
    "xgtest = xgb.DMatrix(df_test_X)\n",
    "\n",
    "predictions = xgc.predict(xgtest)\n",
    "\n",
    "pred_class = (predictions > 0.5).astype(\"int\") \n",
    "actuals = df_test[target_col]\n",
    "print(\"Accuracy on test: {:.2f}\".format(accuracy_score(pred_class, actuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57233054-6905-46e1-83b3-88f610542c3f",
   "metadata": {},
   "source": [
    "Generally speaking, feature importance quantifies how useful each feature was in the construction of the model. We can interrogate a fitted XGBoost model on the feature importance and get the numbers for each one of the individual features.\n",
    "\n",
    "Indirectly, this tells us how much each feature contributes to the model predictions. There is a method called `plot_importance`, which. plots the attribute importance based on the fitted trees. This method accepts an argument named `importance_type`, which takes one of the following values and controls how importance is calculated:\n",
    "\n",
    "* gain --- average gain of splits which use the feature. When looking at two features, the one with the higher gain is more important for generating a prediction. Typically, Gain is the most relevant attribute to interpret the relative importance of each feature.\n",
    "* weight --- number of times a feature appears in a tree. \n",
    "* cover --- average coverage of splits which use the feature where coverage is defined as the number of samples affected by the split. This basically gives us the relative number of observations related to a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70efce-7f69-434b-80c0-afe6fc181aff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(xgc, importance_type=\"gain\", max_num_features=10, show_values=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c01786c-8b0f-40b5-acaf-ac84665fb01f",
   "metadata": {},
   "source": [
    "Based on the above we see that the top three features driving the predictions of the model are:\n",
    "\n",
    "* checking_account_A14 - lack of a checking account\n",
    "* credit_history_A34 - critical account / has credits outside of the bank\n",
    "* property_A121 - real estate\n",
    "\n",
    "We could also look at the other importance metrics, just for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1090c363-4df5-4962-8362-da0573a52125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(xgc, importance_type=\"weight\", max_num_features=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fff081-cbad-4099-857b-0930ddb3d988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(xgc, importance_type=\"cover\", max_num_features=10, show_values=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c28032c-a5b6-4342-b473-4e963e6bc43a",
   "metadata": {},
   "source": [
    "ELI5 is another popular libarary for model explainability. This package is used to debug machine learning classifiers and explain their predictions. \n",
    "\n",
    "Unlike XGBoost, which is confined to explaining its own models only, ELI5 provides support for other frameworks like *scikit-learn*, *Keras*, *LightGBM* and others. It can also explain black-box models (i.e. Neural Networks) using [LIME](https://www.dominodatalab.com/blog/explaining-black-box-models-using-attribute-importance-pdps-and-lime).\n",
    "\n",
    "First, ELI5 also provides a way of calculating the feature importance. Let's test it and make sure it agrees with the original XGBoost calculation (based on gain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b3060-29af-4f93-b541-eeb7742ac2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eli5.show_weights(xgc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3dcac3-26b7-475a-ae48-2a8e7763c745",
   "metadata": {},
   "source": [
    "A more interesting function is `show_predictions`, which returns an explanation of the decision behind individual predictions. In other words, we can see what features drove the model to predict one outcome or the other.\n",
    "\n",
    "Feel free to experiment with the code below, changing the `id` value and observing what features the model uses to calculate its prediction, and if the prediction agrees with the actual value. The `id` variable represents an observation number from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13857734-246a-455b-bda9-fc59891227c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = 3 # <- change this to see results for different observations  \n",
    "\n",
    "print(\"Actual Label: %s\" % actuals.iloc[id])\n",
    "print(\"Predicted: %s\" % pred_class[id])\n",
    "eli5.show_prediction(xgc, df_test_X.iloc[id], \n",
    "                     feature_names=list(df_test_X.columns),\n",
    "                     show_feature_values=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc4438f-81d2-4567-8f36-d583b5376b7e",
   "metadata": {},
   "source": [
    "This concludes the model training notebook demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd20567-0c83-4678-969a-e110d70dde31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set some default values\n",
    "column_names_all = ['duration', 'credit_amount', 'installment_rate', 'residence', 'age', 'credits', 'dependents', 'checking_account_A11', 'checking_account_A12', 'checking_account_A13', 'checking_account_A14', 'credit_history_A30', 'credit_history_A31',\n",
    "                    'credit_history_A32', 'credit_history_A33', 'credit_history_A34', 'purpose_A40', 'purpose_A41', 'purpose_A410', 'purpose_A42', 'purpose_A43', 'purpose_A44', 'purpose_A45', 'purpose_A46', 'purpose_A48', 'purpose_A49', 'savings_A61', \n",
    "                    'savings_A62', 'savings_A63', 'savings_A64', 'savings_A65', 'employment_since_A71', 'employment_since_A72', 'employment_since_A73', 'employment_since_A74', 'employment_since_A75', 'status_A91', 'status_A92', 'status_A93', 'status_A94', \n",
    "                    'debtors_guarantors_A101', 'debtors_guarantors_A102', 'debtors_guarantors_A103', 'property_A121', 'property_A122', 'property_A123', 'property_A124', 'other_installments_A141', 'other_installments_A142', 'other_installments_A143', 'housing_A151', \n",
    "                    'housing_A152', 'housing_A153', 'job_A171', 'job_A172', 'job_A173', 'job_A174', 'telephone_A191', 'telephone_A192', 'foreign_worker_A201', 'foreign_worker_A202']\n",
    "\n",
    "sample_data = [[0.4705882352941176, 0.3685484758446132, 0.3333333333333333, 0.3333333333333333, \n",
    "                0.2857142857142857, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, \n",
    "                1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "                1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, \n",
    "                1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28ce09-fcba-416d-9c12-1297f0e10b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(sample_data, columns=column_names_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98984cd-4370-40e7-ae19-b0514c7acd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in ['checking_account_A11', 'checking_account_A12', 'checking_account_A13', 'checking_account_A14', \n",
    "                'credit_history_A30', 'credit_history_A31', 'credit_history_A32', 'credit_history_A33', \n",
    "                'credit_history_A34', 'purpose_A40', 'purpose_A41', 'purpose_A410', 'purpose_A42', 'purpose_A43', \n",
    "                'purpose_A44', 'purpose_A45', 'purpose_A46', 'purpose_A48', 'purpose_A49', 'savings_A61', \n",
    "                'savings_A62', 'savings_A63', 'savings_A64', 'savings_A65', 'employment_since_A71', \n",
    "                'employment_since_A72', 'employment_since_A73', 'employment_since_A74', 'employment_since_A75', \n",
    "                'status_A91', 'status_A92', 'status_A93', 'status_A94', 'debtors_guarantors_A101', \n",
    "                'debtors_guarantors_A102', 'debtors_guarantors_A103', 'property_A121', 'property_A122', \n",
    "                'property_A123', 'property_A124', 'other_installments_A141', 'other_installments_A142', \n",
    "                'other_installments_A143', 'housing_A151', 'housing_A152', 'housing_A153', 'job_A171', 'job_A172', \n",
    "                'job_A173', 'job_A174', 'telephone_A191', 'telephone_A192', 'foreign_worker_A201', 'foreign_worker_A202']:\n",
    "    df_all[col] = df_all[col].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa566f-d8df-4e0b-afbd-4c572f5d6373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eli5.show_prediction(xgc, df_all.iloc[0], \n",
    "                         feature_names=list(df_all.columns),\n",
    "                         show_feature_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22065cd-e32d-4125-bcfe-ffebe5afde04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd93de67-305c-4216-bdba-e4e62fe6bf59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all.iloc[0][\"checking_account_A14\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b2922c-1200-4973-a537-799b74236270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_prediction = eli5.explain_prediction_df(xgc, df_all.iloc[0], \n",
    "                         feature_names=list(df_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b849c9f-10d8-4c8c-8592-ffc883e2022d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_prediction.head(10).style.background_gradient(cmap = \"Greens\").hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37623a2-b79b-498c-ac35-7c9caf4a93d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
